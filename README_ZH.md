# 优秀的进攻性安全 AI

精选的优秀进攻性安全 AI 工作、论文、组织、库和基准。

## 基准与评估

### CTFTiny (Shao et al.)

一个包含 50 个不同类别挑战的轻量级 CTF 基准。(提交日期: 2025 年 8 月 5 日)

- [Towards Effective Offensive Security LLM Agents 论文](https://arxiv.org/abs/2508.05674)
- [CTFTiny (Shao et al.) GitHub](https://github.com/NYU-LLM-CTF/CTFTiny)

### CyberGym

评估 AI 代理在真实世界中的网络安全能力。(提交日期: 2025 年 6 月 4 日)

- [CyberGym 网站](https://www.cybergym.io/)
- [CyberGym 博客文章](https://rdi.berkeley.edu/blog/cybergym/)
- [CyberGym 数据集](https://huggingface.co/datasets/sunblaze-ucb/cybergym)
- [CyberGym GitHub](https://github.com/sunblaze-ucb/cybergym)
- [CyberGym 论文](https://arxiv.org/abs/2506.02548)

### 网络众包启发

通过众包启发评估 AI 网络能力。 (发布日期: 2025 年 7 月 8 日)

- [网络众包启发博客文章](https://palisaderesearch.org/blog/cyber-crowdsourced-elicitation)

### CVE-Bench

CVE-Bench: 一个用于评估 AI 代理利用真实世界网络漏洞能力的基准。（提交日期：2025 年 3 月 17 日）

- [CVE-Bench GitHub](https://github.com/uiuc-kang-lab/cve-bench)
- [CVE-Bench 论文](https://arxiv.org/abs/2503.17332)

### QHackBench

QHackBench: 使用 PennyLane Hackathon 挑战基准测试用于量子代码生成的大型语言模型。（提交日期：2025 年 6 月 24 日）

- [QHackBench 论文](https://arxiv.org/abs/2506.20008)

### Bountybench

一个捕捉不断发展的真实世界系统中攻防网络能力的框架。（提交日期：2025 年 5 月 21 日）

- [Bountybench 网站](https://bountybench.github.io/)
- [Bountybench GitHub](https://github.com/bountybench/bountybench)
- [Bountybench 论文](https://arxiv.org/abs/2505.15216)

### nyuctf_agents

nyuctf_agents: NYU CTF 基准的基线 LLM 代理。（最新发布：2025 年 2 月 6 日）

- [nyuctf_agents GitHub](https://github.com/NYU-LLM-CTF/nyuctf_agents)
- [NYU_CTF_BenchMark](https://github.com/NYU-LLM-CTF/NYU_CTF_Bench)

### InterCode-CTF

InterCode-CTF: 一个用于评估 LLM 在夺旗挑战中表现的基准。（提交日期：2024 年 12 月 3 日）

- [InterCode-CTF 博客文章](https://palisaderesearch.org/blog/intercode-ctf)
- [论文: Hacking CTFs with Plain Agents](https://arxiv.org/abs/2412.02776)
- [intercode GitHub](https://github.com/palisaderesearch/intercode)

### Cybench

Cybench: 一个评估语言模型网络安全能力和风险的框架。（提交日期：2024 年 8 月 15 日）

- [Cybench 网站](https://cybench.github.io/)
- [Cybench GitHub](https://github.com/andyzorigin/cybench)
- [Cybench 论文](https://arxiv.org/abs/2408.08926)
- [ICLR 2025 大会议题](https://iclr.cc/virtual/2025/oral/31753)

### CYBERSECEVAL 3

CYBERSECEVAL 3: 推进大型语言模型网络安全风险和能力的评估。（提交日期：2024 年 8 月）

- [CYBERSECEVAL 3 论文](https://arxiv.org/abs/2408.10627)

### CyberMetric

CyberMetric: 一个基于检索增强生成的基准数据集，用于评估 LLM 在网络安全知识方面的能力。（提交日期：2024 年 7 月）

- [CyberMetric 论文](https://arxiv.org/abs/2407.08CyberMetric)
- [CyberMetric 数据集](https://huggingface.co/datasets/norbert-tihanyi/CyberMetric)

### SEvenLLM

SEvenLLM: 一个旨在引出和提高 LLM 在安全事件中进行网络安全事件分析和响应能力的基准。（提交日期：2024 年 5 月）

- [SEvenLLM 论文](https://arxiv.org/abs/2405.18354)
- [SEvenLLM GitHub](https://github.com/7evenllm/SEvenLLM)

### CyberSecEval_2

CYBERSECEVAL 2: 一个广泛的网络安全评估套件，用于大型语言模型。（提交日期：2024 年 4 月）

- [CyberSecEval 2 论文](https://arxiv.org/abs/2404.07920)
- [CyberSecEval 2 GitHub](https://github.com/meta-llama/cyberseceval)

### GDM Dangerous Capabilities

GDM Dangerous Capabilities: 夺旗挑战。（提交日期：2024 年 3 月）

- [GDM Dangerous Capabilities 论文](https://arxiv.org/abs/2403.13793)
- [GDM Dangerous Capabilities GitHub](https://github.com/google-deepmind/evals/tree/main/dangerous_capabilities)

### LLM_CTF

LLM 解决进攻性安全挑战的实证评估。（提交日期：2024 年 2 月 19 日）

- [LLM_CTF GitHub](https://github.com/NickNameInvalid/LLM_CTF)
- [LLM_CTF 论文](https://arxiv.org/abs/2402.11814)

### SecQA

SecQA: 一个简洁的问答数据集，用于评估大型语言模型在计算机安全方面的能力。（提交日期：2023 年 12 月）

- [SecQA 论文](https://arxiv.org/abs/2312.07344)
- [SecQA 数据集](https://huggingface.co/datasets/secqa/secqa-v2)

## LLM 代理与框架

### Cyber-AutoAgent

一个先进的自主网络安全代理，利用元代理架构动态调整其策略和工具，以进行复杂的渗透测试。 (发布日期: 2025 年 11 月)

- [Cyber-AutoAgent GitHub](https://github.com/westonbrown/Cyber-AutoAgent)
- [从单代理到元代理 博客文章](https://medium.com/data-science-collective/from-single-agent-to-meta-agent-building-the-leading-open-source-autonomous-cyber-agent-e1b704f81707)
- [从 XBOW 基准测试中学习架构经验 博客文章](https://medium.com/data-science-collective/building-the-leading-open-source-pentesting-agent-architecture-lessons-from-xbow-benchmark-f6874f932ca4)

### Strix

一个由 AI 驱动的渗透测试代理，可帮助开发人员和安全工程师保护其 Web 应用程序。 (首次提交: 2024 年 7 月)

- [Strix 网站](https://usestrix.com/)
- [Strix GitHub](https://github.com/usestrix/strix)

### Towards Effective Offensive Security LLM Agents (迈向高效的进攻性安全 LLM 代理)

迈向高效的进攻性安全 LLM 代理：超参数调整、LLM 作为裁判以及轻量级 CTF 基准。(提交日期: 2025 年 8 月 5 日)

- [Towards Effective Offensive Security LLM Agents 论文](https://arxiv.org/abs/2508.05674)
- [CTFTiny GitHub](https://github.com/NYU-LLM-CTF/CTFTiny)

### Incalmo

一个高级抽象层，允许 LLM 指定一般性动作，然后由专家代理将其转换为具体命令。(提交日期: 2025 年 1 月 28 日)

- [关于使用 LLM 自主执行多主机攻击的可行性 论文](https://arxiv.org/abs/2501.16466)

#### CRAKEN

CRAKEN: 具有基于知识执行的网络安全 LLM 代理。（提交日期：2025 年 5 月 21 日）

- [CRAKEN GitHub](https://github.com/NYU-LLM-CTF/nyuctf_agents_craken)
- [CRAKEN 论文](https://arxiv.org/abs/2505.17107)

### RedTeamLLM

RedTeamLLM: 一个用于进攻性安全的 Agentic AI 框架。（提交日期：2025 年 5 月 11 日）

- [RedTeamLLM 论文](https://arxiv.org/abs/2505.06913)
- [RedTeamLLM GitHub](https://github.com/lre-security-systems-team/redteamllm)

### HackSynth-GRPO

HackSynth-GRPO: 一个利用引导式强化提示优化 (GRPO) 来增强 LLM 代理解决密码学 CTF 挑战的框架。（发布日期：2025 年 4 月）

- [HackSynth-GRPO 论文](https://arxiv.org/html/2506.02048)
- [HackSynth-GRPO GitHub](https://github.com/aielte-research/HackSynth-GRPO)

### CAI

一个轻量级、符合人体工程学的框架，用于构建可用于漏洞赏金的 AI 网络安全（CAI）。（论文发布：2025 年 4 月）

- [CAI 网站](https://aliasrobotics.github.io/cai/)
- [CAI GitHub](https://github.com/aliasrobotics/cai)

#### D-CIPHER

D-CIPHER: 进攻性安全的动态协作智能多代理系统。（提交日期：2025 年 2 月 15 日）

- [D-CIPHER 论文](https://arxiv.org/abs/2502.10931)

### CTFTiny

CTFTINY: 用于大型语言模型网络攻击技能的轻量级基准测试。（提交日期：2025 年 2 月 11 日）

- [CTFTiny GitHub](https://github.com/NYU-LLM-CTF/CTFTiny)

### PentestGPT

PentestGPT: 一个由 GPT 驱动的渗透测试工具。（发布日期：2024 年 8 月 12 日）

- [PentestGPT GitHub](https://github.com/GreyDGL/PentestGPT)
- [PentestGPT 论文](https://www.usenix.org/conference/usenixsecurity24/presentation/deng)

### HackSynth

HackSynth: 用于自主渗透测试的 LLM 代理和评估框架。（提交日期：2024 年 12 月 2 日）

- [HackSynth GitHub](https://github.com/aielte-research/HackSynth)
- [HackSynth 论文](https://arxiv.org/abs/2412.01778)

### EnIGMA

EnIGMA: 一种解决进攻性网络安全（夺旗）挑战的模式，在多个网络安全基准上取得了最先进的结果。（提交日期：2024 年 9 月 24 日）

- [EnIGMA 网站](https://enigma-agent.com)
- [EnIGMA GitHub](https://github.com/SWE-agent)
- [EnIGMA 论文](https://arxiv.org/abs/2409.16165)
- [EnIGMA 基准](https://github.com/enigma-agent/benchmarks)

### XBOW(商业)

XBOW: 一个自主发现和利用潜在安全漏洞的系统。（首次提交：约 10 个月前）

- [XBOW 网站](https://xbow.com/)
- [XBOW 基准](https://github.com/xbow-engineering/validation-benchmarks)
- [XBOW 安全咨询致谢](https://github.com/advisories?query=credit%3Axbow-security)
- [AI Agents for OffSec with Zero False Positives (Black Hat 2025 幻灯片)](https://assets-global.website-files.com/658189b90f81ce5f1a7e6d63/66ac8e51655997008e75f733_XBOW%20-%20Black%20Hat%202025%20-%20AI%20Agents%20for%20Offsec%20with%20Zero%20False%20Positives.pdf)

### 从脚本到策略：Claude 4 在进攻性安全中的高级方法

Pattern Labs 和 Anthropic 对 Claude 4 在进攻性安全方面的能力进行的联合评估。(发布日期: 2025 年 8 月 20 日)

- [从脚本到策略：Claude 4 在进攻性安全中的高级方法 博客文章](https://patternlabs.co/blog/from-scripts-to-strategy-claude-4s-advanced-approach-to-offensive-security)

## 竞赛

### Agentic Automated CTF

一项挑战参与者构建由大型语言模型（LLM）驱动的 AI 代理，以自主解决夺旗（CTF）挑战的竞赛。

- [Agentic Automated CTF 网站](https://www.csaw.io/agentic-automated-ctf)

### AI Cyber Challenge

AI Cyber Challenge: 一项旨在推进网络安全领域人工智能技术水平的竞赛。

- [AI Cyber Challenge 网站](https://aicyberchallenge.com/)

### 网络竞赛

网络竞赛的最新趋势和结果简报。(发布日期: 2025 年 11 月)

- [网络竞赛博客文章](https://red.anthropic.com/2025/cyber-competitions/)

### 腾讯云黑客松-智能渗透挑战赛

基于 XBOW Benchmark 设计赛题。参赛选手需编写以大语言模型（LLM）为核心驱动的智能体程序，完成靶机的自动化渗透并获取 FLAG。 (2025-11-08 至 2025-11-17)

- [智能渗透挑战赛](https://zc.tencent.com/competition/competitionHackathon?code=cha004)

#### Top 4 Antix

- [意图工程(Intent Engineering)：Agent Pattern Graph(APG) & Meta Tooling](https://wiki.chainreactors.red/blog/2025/12/02/intent_engineering_01)

- [Intent Is All You Need (for agent)](https://mp.weixin.qq.com/s/GOfV2JDo6c7r36BNeHtG2g)

- [AI for 安全攻防：自动化渗透 Agent 的工程设计与实践](https://mp.weixin.qq.com/s/jT4poWZ4Gfu3faXvul07HA)

#### Top 9 yhy for yhy

- [7 天 Top 9：我如何让 Claude 手搓一个全自动 CTF 选手](https://mp.weixin.qq.com/s/fWWVMTySJMpyKt62BBsDdA)
- [CHYing-agent](https://github.com/yhy0/CHYing-agent)

## LLM 安全研究与工具

### AI 代理发现了 460 万美元的区块链智能合约漏洞

- [文章](https://red.anthropic.com/2025/smart-contracts/)

### AI for Cyber Defenders

探讨 AI 在网络防御中的应用，从威胁检测到事件响应。(发布日期: 2025 年 11 月)

- [AI for Cyber Defenders 博客文章](https://red.anthropic.com/2025/ai-for-cyber-defenders/)

### 安全论文和链接 (SPL)

安全论文和链接的集合。(更新日期: 2025)

- [SPL 网站](https://spl.team/)

### 教 LLM 如何 XSS

教 LLM 如何 XSS: 微调和强化学习的介绍（使用您自己的 GPU）

- [幻灯片](https://docs.google.com/presentation/d/1feHRtOWdAKhZUQcfyzeDSgsx4Sn5QzqfgLFV1Tiskmo/edit)

### inspect_cyber

inspect_cyber: 由 UKGovernmentBEIS 开发的 Inspect 扩展，旨在用于代理网络评估。该项目旨在促进网络安全领域中 AI 代理的评估。

- [inspect_cyber 网站](https://inspect.cyber.aisi.org.uk/)
- [inspect_cyber GitHub](https://github.com/UKGovernmentBEIS/inspect_cyber)

## 如何贡献

欢迎贡献！如果您有适合此列表的项目、论文或资源，请随时提交拉取请求。请确保您的提交符合现有格式和类别。
